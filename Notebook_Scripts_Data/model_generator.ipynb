{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7501912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1f90d4",
   "metadata": {},
   "source": [
    "## making labels and creating filenames in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f99ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 CRN          Full Name\n",
      "count             48                 48\n",
      "unique            48                 48\n",
      "top     KCE074BCT001  AAKASH RAJ DHAKAL\n",
      "freq               1                  1\n",
      "            CRN          Full Name\n",
      "0  KCE074BCT001  AAKASH RAJ DHAKAL\n",
      "1  KCE074BCT002    AAKASH SHRESTHA\n",
      "2  KCE074BCT003     AAKRITI AGANJA\n",
      "3  KCE074BCT004     AAYUSH MUSYAJU\n",
      "4  KCE074BCT005      ABHINAV ARYAL\n"
     ]
    }
   ],
   "source": [
    "labels_csv = pd.read_csv(\"crnAndName.csv\")\n",
    "print(labels_csv.describe())\n",
    "print(labels_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae66315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['KCE074BCT001', 'KCE074BCT002', 'KCE074BCT003', 'KCE074BCT004',\n",
       "       'KCE074BCT005', 'KCE074BCT006', 'KCE074BCT007', 'KCE074BCT008',\n",
       "       'KCE074BCT009', 'KCE074BCT010', 'KCE074BCT011', 'KCE074BCT012',\n",
       "       'KCE074BCT013', 'KCE074BCT014', 'KCE074BCT015', 'KCE074BCT016',\n",
       "       'KCE074BCT017', 'KCE074BCT018', 'KCE074BCT019', 'KCE074BCT020',\n",
       "       'KCE074BCT021', 'KCE074BCT022', 'KCE074BCT023', 'KCE074BCT024',\n",
       "       'KCE074BCT025', 'KCE074BCT026', 'KCE074BCT027', 'KCE074BCT028',\n",
       "       'KCE074BCT029', 'KCE074BCT030', 'KCE074BCT031', 'KCE074BCT032',\n",
       "       'KCE074BCT033', 'KCE074BCT034', 'KCE074BCT035', 'KCE074BCT036',\n",
       "       'KCE074BCT037', 'KCE074BCT038', 'KCE074BCT039', 'KCE074BCT040',\n",
       "       'KCE074BCT041', 'KCE074BCT042', 'KCE074BCT043', 'KCE074BCT044',\n",
       "       'KCE074BCT045', 'KCE074BCT046', 'KCE074BCT047', 'KCE074BCT048'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert labels column to NumPy array\n",
    "unique_labels=labels_csv['CRN'].to_numpy()\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e08bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/KCE074BCT001',\n",
       " 'data/KCE074BCT002',\n",
       " 'data/KCE074BCT003',\n",
       " 'data/KCE074BCT004',\n",
       " 'data/KCE074BCT005']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "filedir=[\"data/\"+crn for crn in unique_labels]\n",
    "filedir[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc1908d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=[]\n",
    "labels=[]\n",
    "for dir in filedir:\n",
    "    files=os.listdir(dir)\n",
    "    for file in files:\n",
    "        filetemp=dir+'/'+file\n",
    "        filenames.append(filetemp)\n",
    "        labels.append(dir[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "408eccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4700"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking files and labels available\n",
    "print(len(filenames))\n",
    "len((labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "113349ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/KCE074BCT001/1.jpg', 'data/KCE074BCT001/1_B_0.125.jpg', 'data/KCE074BCT001/1_B_0.25.jpg', 'data/KCE074BCT001/1_B_0.375.jpg', 'data/KCE074BCT001/1_B_0.5.jpg']\n",
      "['KCE074BCT001', 'KCE074BCT001', 'KCE074BCT001', 'KCE074BCT001', 'KCE074BCT001']\n"
     ]
    }
   ],
   "source": [
    "#checking labels and file name\n",
    "print(filenames[:5])\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2876d7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KCE074BCT001' 'KCE074BCT001' 'KCE074BCT001' ... 'KCE074BCT048'\n",
      " 'KCE074BCT048' 'KCE074BCT048']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_labels=np.asarray(labels)\n",
    "print(np_labels)\n",
    "type(np_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b428aecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KCE074BCT001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Turn one label into an array of booleans\n",
    "print(labels[0])\n",
    "labels[0] == unique_labels # use comparison operator to create boolean array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de5fd68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True]),\n",
       " array([False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn every label into a boolean array\n",
    "boolean_labels = [label == np.array(unique_labels) for label in labels]\n",
    "boolean_labels[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "428cea0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KCE074BCT001\n",
      "0\n",
      "0\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Example: Turning a boolean array into integers\n",
    "print(labels[0]) # original label\n",
    "print(np.where(unique_labels == labels[0])[0][0]) # index where label occurs\n",
    "print(boolean_labels[0].argmax()) # index where label occurs in boolean array\n",
    "print(boolean_labels[0].astype(int)) # there will be a 1 where the sample label occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bc5565",
   "metadata": {},
   "source": [
    "## creating validation list in small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b1ca925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup X & y variables\n",
    "X = filenames\n",
    "y = np_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ec4ed01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set number of images to use for experimenting\n",
    "NUM_IMAGES = 1000 #@param {type:\"slider\", min:1000, max:10000, step:1000}\n",
    "NUM_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44591d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 800, 200, 200)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import train_test_split from Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split them into training and validation using NUM_IMAGES \n",
    "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],\n",
    "                                                  y[:NUM_IMAGES], \n",
    "                                                  test_size=0.2,\n",
    "                                                 random_state=42)\n",
    "\n",
    "len(X_train), len(y_train), len(X_val), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d43e9512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['data/KCE074BCT001/1_C_1.75.jpg',\n",
       "  'data/KCE074BCT005/4_C_0.375.jpg',\n",
       "  'data/KCE074BCT006/1_R_35.jpg',\n",
       "  'data/KCE074BCT005/4_R_50.jpg',\n",
       "  'data/KCE074BCT007/2_R_35.jpg'],\n",
       " array(['KCE074BCT001', 'KCE074BCT005', 'KCE074BCT006', 'KCE074BCT005',\n",
       "        'KCE074BCT007'], dtype='<U12'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5], y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2bc126",
   "metadata": {},
   "source": [
    "## Preprocessing images (turning images into Tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82313bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 176, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert image to NumPy array\n",
    "from matplotlib.pyplot import imread\n",
    "image = imread(filenames[0]) # read in an image\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20f5688f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 176, 3), dtype=uint8, numpy=\n",
       "array([[[173, 140, 123],\n",
       "        [195, 159, 143],\n",
       "        [198, 159, 144],\n",
       "        ...,\n",
       "        [ 69,  45,  43],\n",
       "        [ 54,  29,  25],\n",
       "        [ 41,  16,  12]],\n",
       "\n",
       "       [[171, 135, 119],\n",
       "        [177, 140, 124],\n",
       "        [183, 144, 127],\n",
       "        ...,\n",
       "        [ 70,  46,  44],\n",
       "        [ 69,  45,  41],\n",
       "        [ 59,  34,  30]]], dtype=uint8)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.constant convert list into tensor\n",
    "tf.constant(image)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98629c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size\n",
    "IMG_SIZE = 160\n",
    "\n",
    "def process_image(image_path):\n",
    "  \"\"\"\n",
    "  Takes an image file path and turns it into a Tensor.\n",
    "  \"\"\"\n",
    "  image = tf.io.read_file(image_path)\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb272f",
   "metadata": {},
   "source": [
    "## Creating data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "940b929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple function to return a tuple (image, label)\n",
    "def get_image_label(image_path, label):\n",
    "  \"\"\"\n",
    "  Takes an image file path name and the associated label,\n",
    "  processes the image and returns a tuple of (image, label).\n",
    "  \"\"\"\n",
    "  image = process_image(image_path)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa99528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size, 32 is a good default\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create a function to turn data into batches\n",
    "def create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
    "    if test_data:\n",
    "        print(\"Creating test data batches...\")\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n",
    "        data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
    "        return data_batch\n",
    "  \n",
    "    elif valid_data:\n",
    "        print(\"Creating validation data batches...\")\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(x),tf.constant(y)))\n",
    "        data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
    "        return data_batch\n",
    "    else:\n",
    "        print(\"Creating training data batches...\")\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(x),tf.constant(y)))# filenames                                                 \n",
    "        data = data.shuffle(buffer_size=len(x))\n",
    "# Create (image, label) tuples (this also turns the image path into a preprocessed image)\n",
    "        data = data.map(get_image_label)\n",
    "        data_batch = data.batch(BATCH_SIZE)\n",
    "    return data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00ad2aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test data batches...\n",
      "Creating test data batches...\n"
     ]
    }
   ],
   "source": [
    "# Create training and validation data batches\n",
    "train_data = create_data_batches(X_train,test_data=True)\n",
    "val_data = create_data_batches(X_val,test_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab6b2513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the different attributes of our data batches\n",
    "train_data.element_spec, val_data.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c468b960",
   "metadata": {},
   "source": [
    "## Visualizing data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1697db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a function for viewing images in a data batch\n",
    "def show_25_images(images, labels):\n",
    "  \"\"\"\n",
    "  Displays 25 images from a data batch.\n",
    "  \"\"\"\n",
    "  # Setup the figure\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  # Loop through 25 (for displaying 25 images)\n",
    "  for i in range(25):\n",
    "    ax = plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(unique_labels[labels[i].argmax()])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8da19bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GAMERU~1\\AppData\\Local\\Temp/ipykernel_10328/4126820407.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize training images from the training data batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mshow_25_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Visualize training images from the training data batch\n",
    "train_images, train_labels = next(train_data.as_numpy_iterator())\n",
    "show_25_images(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8e1fa73",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GAMERU~1\\AppData\\Local\\Temp/ipykernel_10328/4104824148.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize validation images from the validation data batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mval_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mshow_25_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Visualize validation images from the validation data batch\n",
    "val_images, val_labels =next(val_data.as_numpy_iterator())\n",
    "show_25_images(val_images, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0a7af",
   "metadata": {},
   "source": [
    "## Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a0e6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup input shape to the model\n",
    "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e3849db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 160, 160, 3]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7546b2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#find embeddings\n",
    "model = load_model('facenet_keras.h5')\n",
    "yhat = model.predict(train_data)\n",
    "val = model.predict(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd7997bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 128)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have embedding of 800 images\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe9fbbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 128)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48c76396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0535204 ,  0.05586003,  1.7992429 , ...,  0.20159492,\n",
       "        -0.8022081 ,  0.47870997],\n",
       "       [-0.02435495,  0.2934029 , -1.6854384 , ..., -1.139411  ,\n",
       "         0.2718387 ,  0.3479242 ],\n",
       "       [ 0.41750345,  1.0129901 ,  0.27377045, ...,  0.20721921,\n",
       "        -0.61479145,  0.61908835],\n",
       "       ...,\n",
       "       [ 0.87212324,  0.9842222 , -1.3399814 , ..., -0.9932738 ,\n",
       "        -0.7196422 , -0.27793187],\n",
       "       [ 1.1606534 ,  0.6037433 , -1.2772365 , ..., -0.8889854 ,\n",
       "         0.3149119 , -1.5303124 ],\n",
       "       [-0.7101233 , -0.0794994 ,  1.3654355 , ..., -0.14589366,\n",
       "        -0.71568674,  0.13996154]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11b8275d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0481049e+00,  1.8711913e-01, -2.2016571e+00, ...,\n",
       "        -1.9788603e+00,  4.3282637e-01, -1.1010208e+00],\n",
       "       [-3.1849253e-01,  8.3563948e-01,  1.0949095e+00, ...,\n",
       "         2.0426437e-03, -1.4639783e-01,  1.3033355e+00],\n",
       "       [-1.6753902e-01,  6.8292117e-01,  4.4091484e-01, ...,\n",
       "         6.6889860e-02, -1.8283600e-01,  1.7719328e+00],\n",
       "       ...,\n",
       "       [ 7.9389405e-01, -6.3543236e-01, -2.0107162e-01, ...,\n",
       "         7.1250933e-01, -1.1107912e+00, -3.9632615e-01],\n",
       "       [-1.3509084e-01, -4.9055859e-01, -2.7893808e-01, ...,\n",
       "        -6.3941938e-01,  1.5431622e-01,  5.6118256e-01],\n",
       "       [ 5.9704237e-02,  2.7904397e-01,  6.0864347e-01, ...,\n",
       "        -5.3563339e-01,  1.4930205e-01,  4.2049485e-01]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b4bd8f",
   "metadata": {},
   "source": [
    "## now svc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba01d9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00437162,  0.00456272,  0.14696458, ...,  0.01646654,\n",
       "        -0.06552543,  0.03910167],\n",
       "       [-0.00338937,  0.04083161, -0.23455514, ..., -0.15856688,\n",
       "         0.03783061,  0.0484191 ],\n",
       "       [ 0.03374007,  0.08186366,  0.02212445, ...,  0.01674619,\n",
       "        -0.04968368,  0.05003093],\n",
       "       ...,\n",
       "       [ 0.06997973,  0.07897462, -0.10752098, ..., -0.07970093,\n",
       "        -0.05774456, -0.02230143],\n",
       "       [ 0.09393521,  0.04886278, -0.10337063, ..., -0.07194829,\n",
       "         0.02548678, -0.12385283],\n",
       "       [-0.05771888, -0.00646172,  0.11098271, ..., -0.01185825,\n",
       "        -0.05817108,  0.01137609]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize the embedded data\n",
    "in_encode = Normalizer(norm='l2')\n",
    "trainx = in_encode.transform(yhat)\n",
    "valx = in_encode.transform(val)\n",
    "trainx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad106e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_encode = LabelEncoder()\n",
    "out_encode.fit(y_train)\n",
    "trainy = out_encode.transform(y_train)\n",
    "\n",
    "out_encode.fit(y_val)\n",
    "valy=out_encode.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "73354449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', probability=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define svm classifier model \n",
    "model =SVC(kernel='linear', probability=True)\n",
    "model.fit(trainx,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c70371ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = model.predict(trainx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d9ebde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9475"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(trainx,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3fe42762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(valx,valy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "741082aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=model.predict(valx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e8a8043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_preds==valy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407306d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6430998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82edbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23f31c7e",
   "metadata": {},
   "source": [
    "### Training a model (on a subset of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00f6a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rounds should we get the model to look through the data?\n",
    "NUM_EPOCHS = 100 #@param {type:\"slider\", min:10, max:100, step:10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bdc3c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "16008d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Create a function to build a TensorBoard callback\n",
    "def create_tensorboard_callback():\n",
    "  # Create a log directory for storing TensorBoard logs\n",
    "    logdir = os.path.join(\"logs\",\n",
    "                        # Make it so the logs get tracked whenever we run an experiment\n",
    "                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    return tf.keras.callbacks.TensorBoard(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "42970822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create early stopping (once our model stops improving, stop training)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
    "                                                  patience=3) # stops after 3 rounds of no improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6a7eb72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a function to train and return a trained model\n",
    "def train_model():\n",
    "    \n",
    "    model = InceptionResNetV2()\n",
    "    \n",
    "    tensorboard = create_tensorboard_callback()\n",
    "    \n",
    "    model.fit(x=train_data,\n",
    "              epochs=NUM_EPOCHS,\n",
    "              validation_data=val_data,\n",
    "              validation_freq=1,\n",
    "              callbacks=[tensorboard, early_stopping])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca48c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
